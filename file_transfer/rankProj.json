[{"pk": 1, "model": "rankProj.project", "fields": {"vote_up": 2, "motivation_content": "During my 2nd year of undergraduate at the University of Toronto, I decided to built a Lego Pinball Machine for my Computer Organization Course. Since I was a kid, I have always been a fan of Lego blocks. This is my first Lego project integrating electronic sensors to create an interactive machine.\r\n\r\n\r\n\r\n", "video_url": "http://www.youtube.com/embed/MpPNHwXBnaE", "tags": "Altera, FPGA, Assembly, LEGO", "title": "FPGA Lego Pinball Machine ", "PDF": "none", "base_vote": 10, "link": "project_lego_pinball_machine", "rank_img": "fpga_lego_1.jpg", "authors": "Alexander Chen, Alex Hsiao. ECE243 Computer Organization, University of Toronto. ", "short_description": "A pinball machine controlled by Altera DE2 board. User can control the flippers and ball launcher via regular keyboard. Light sensors are installed in various places to keep track of user's scores.", "complete_date": "2010-04-01", "motivation_image": "/Images/lego_motivation.jpg"}}, {"pk": 2, "model": "rankProj.project", "fields": {"vote_up": 3, "motivation_content": "Meijing is a little puppy, I have spent a lot of time with him through out his childhood. However, every time I go out I feel really guilty leaving him at home and be bored. Therefore, instead of buying another dog and create a huge mess, I decided to make him a robot (A-bot) that will have interaction with him while we were not around. \r\n\r\n\r\n\r\n", "video_url": "http://www.youtube.com/embed/1mNX7OVlNtM", "tags": "Arduino, Remote Control, Puppy, Robot, Car", "title": "Puppy's Best Friend (Robot)", "PDF": "none", "base_vote": 15, "link": "project_puppy_robot", "rank_img": "puppy_meijing_1.jpg", "authors": "Alexander Chen.", "short_description": "A robot that was made to play with the dog while no one is at home. I got lots of interesting reaction from the puppy.", "complete_date": "2011-04-01", "motivation_image": "/Images/puppy_robot_motivation.jpg"}}, {"pk": 3, "model": "rankProj.project", "fields": {"vote_up": 4, "motivation_content": "The programmable LED skateboard is my first project not related to any courses. I have learned so much knowledge in practical electronics and prototyping work flow throughout the process. It made me understand the true meaning of engineering and how joyful life could be if you absolutely love what you do. I realized building technology that changes people's life and make people happy is what I want to do for the rest of my life. \r\n\r\n\r\n\r\n", "video_url": "http://www.youtube.com/embed/095CPMuuJ10", "tags": "LED, Arduino, Safety, Fashion", "title": "Programmable LED Skateboard.", "PDF": "none", "base_vote": 20, "link": "project_ledskateboard", "rank_img": "led_skateboard_v1_2.jpg", "authors": "Alexander Chen, Harrison Chen.", "short_description": "A programmable skateboard that can shine at night. This skateboard make me a super star on the street. ", "complete_date": "2010-09-01", "motivation_image": "/Images/ledskateboard_motivation.jpg"}}, {"pk": 4, "model": "rankProj.project", "fields": {"vote_up": 3, "motivation_content": "While I was in high school, one of my close relatives had an unfortunate stroke. After a series of emergency rescue, her life was saved but the stroke left her body paralyzed and also took away her ability to talk. The only part of her body she have some control with, is her right hand.  \r\n\r\nDuring the years, I have always imagine myself in her shoes. It must be a very difficult mental challenge to not be able to express ones feelings for such a long time. I was helpless and lack of a solution until one day in my ECE516 lecture taught by Prof. Steve Mann. In class, Prof. Mann was talking about a single handed keying device used for performing music and typing English characters. It was then I thought, if my relative can have such a device enable her to type out her feelings, her world will never be the same. It was the first time in my life that I actually can use my engineering skills to help others and make a difference in their lives. It was absolutely amazing.\r\n\r\n\r\n\r\n", "video_url": "http://www.youtube.com/embed/6UP1eFSPfOw", "tags": "Assistive Technology, Japanese, Photo Resistor, Audio & Visual Feedback, Arduino, Processing", "title": "Japanese Medical talking glove", "PDF": "none", "base_vote": 35, "link": "project_jp_talking_glove", "rank_img": "jp_talk_2.jpg", "authors": "Alexander Chen, Harrison Chen.", "short_description": "An assistive device designed to help one of my relative talk again in her life.", "complete_date": "2011-02-01", "motivation_image": "/Images/jp_talk_motivation.jpg"}}, {"pk": 5, "model": "rankProj.project", "fields": {"vote_up": 2, "motivation_content": "Note:This project was done prior taking any course in machine learning.\r\n\r\nOne of my many dreams as a kid was to have super power like those heroic cartoon characters on TV. In particular, I have always wanted to move things simply by 'thinking about it'. For example, I want to turn off the lights just by think about it, get food from the fridge to my table just by thinking about it. \r\n\r\nWhen Prof. Mann introduced to me the Neurosky EEG chip, my dream have come true. After hacking around around with the chip, we were able to perform mind control on RC cars, lights and interactive games. The experience is wonderful. With most of these projects, we basically use the value of concentration and meditation as our main control variable.\r\n\r\nIn order to do more, we need to extract more information from our own brainwave. We need reliable signal that are unique and easy to control with. If you can find such signal, then we can do more complicated mind control on more objects. With this thought in mind, I walked in the world of machine learning and never stop learning it ever since.\r\n\r\n\r\n\r\n", "video_url": "http://www.youtube.com/embed/8UlY7_mUlb0", "tags": "Brainwave, NeuroSky, Real Time, K-means, Naive Bayes, CUDA, GPU", "title": "Real Time Brainwave Clustering & Recognition", "PDF": "none", "base_vote": 25, "link": "project_brainwave", "rank_img": "brainwave_motivation_2.jpg", "authors": "Alexander Chen, Jason Huang, Raymond Lo", "short_description": "An research project hopping to find more information from our own brainwaves in order to do more \"mind control\" on any electronic devices.", "complete_date": "2011-08-01", "motivation_image": "/Images/brainwave_motivation_1.jpg /Images/brainwave_motivation_2.jpg"}}, {"pk": 6, "model": "rankProj.project", "fields": {"vote_up": 2, "motivation_content": "This projected was inspired by Professor Steve Mann while I was taking the course ECE516 Intelligent Image Processing in my 3rd year of undergraduate at the University of Toronto. Near the end of the winter semester 2011, Professor Mann gave us the idea of 'Seeing through Kinect' and use it as a wearable computer.We thought the idea was really cool so I joined up with Jason & Taqveer to hack out the first prototype in one night.", "video_url": "http://www.youtube.com/embed/CKQNpUH_ZVo", "tags": "Assistive Technology, Vision, Kinect, Vibration Sensor, Halmet", "title": "Blind navigation with a wearable range camera and vibrotactile helmet.", "PDF": "acmmm2011kinectHelmet_camready.pdf", "base_vote": 30, "link": "project_kinect_visual", "rank_img": "kinect_vision_3.jpg", "authors": "Steve Mann, Jason Huang, Ryan Janzen, Raymond Lo, Valmiki Rampersad, Alexander Chen, Taqveer Doha. MM '11 Proceedings of the 19th ACM international conference on Multimedia.", "short_description": "A research project use Kinect to help blind people navigate. This project is published as a paper.", "complete_date": "2011-04-01", "motivation_image": "/Images/kinect_motivation.jpg"}}, {"pk": 7, "model": "rankProj.project", "fields": {"vote_up": 2, "motivation_content": "This project is my first project after I joined the Prof. Steve Mann's team in the Intelligent Image Processing Lab at the University of Toronto. Thanks to this project, I have the chance to know some great people and get exposure to lots of practical electronics application and software algorithms.\t\t\t\t\t\t\t\t\t\t\t\t\t\r\n\r\nDuring the summer research period, Prof. Mann took the team to perform weekly music performance across Art Gallery Ontario. Combined with hot summer heat, the team set up amplifiers and various inventions of water instruments and create great musics. On a normal day, lots of people will come by listen to the music and asked around. It was a life changing experience. \r\n", "video_url": "http://www.youtube.com/embed/q_HjVMthlKI", "tags": "Water-Hammer effect, hydraulophone", "title": "User-interfaces based on the water-hammer effect: water-hammer piano as an interactive percussion surface. ", "PDF": "WaterHammerPiano_tei2011.pdf", "base_vote": 5, "link": "project_waterhammer_piano", "rank_img": "waterhammer_piano_2.jpg", "authors": "Steve Mann, Ryan Janzen, Jason Huang, Matthew Kelly, Lei Jimmy Ba, Alexander Chen.  TEI '11 Proceedings of the fifth international conference on Tangible, embedded, and embodied interaction. ", "short_description": "A water instrument. This project is published as a paper.", "complete_date": "2010-08-01", "motivation_image": "/Images/waterhammer_piano_motivation.jpg"}}, {"pk": 1, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 0, "project": 1, "feature_content": "This project used Altera DE2 as the processor and various other units to pass input/output between the processor and the sensors. Light sensors are used to count scores and Motors are used to perform user's actions. The software portion of the project is done in assembly code.\r\n\r\n\r\n\r\n", "feature_order": 1, "feature_title": "intro"}}, {"pk": 2, "model": "rankProj.feature", "fields": {"feature_image": "/Images/fpga_lego_feature_1.jpg", "display_choice": 2, "project": 1, "feature_content": "There is a total of 3 motors being used in this project. 1 motor for the pinball launcher, the other 2 motors for the flippers. All motors will be triggered when user type in the corresponding character on the keyboard.\r\n\r\nWhen the key is pressed, an interrupt signal is raised in the code so the code will jump into the interrupt handler and execute the expected action. After the corresponding action is executed, the code will continue execute the code where it left off before the interrupt.\r\n\r\n\r\n\r\n", "feature_order": 2, "feature_title": "Motors"}}, {"pk": 3, "model": "rankProj.feature", "fields": {"feature_image": "/Images/fpga_lego_feature_2.jpg", "display_choice": 2, "project": 1, "feature_content": "There is a total of 4 light sensors used in this project. 2 under the skeleton symbol on the top of the pinball machine. and 1 on each side close to the tunnel. The software use an infinite loop looping through all the sensor values. Since there is only 4 light sensors, the processor is able to loop through all of them fast enough without missing any read of score increments.\r\n\r\n\r\n\r\n", "feature_order": 3, "feature_title": "Light Sensors"}}, {"pk": 4, "model": "rankProj.feature", "fields": {"feature_image": "/Images/fpga_lego_feature_3.jpg", "display_choice": 2, "project": 1, "feature_content": "The keyboard served as the input device for the user. Once the corresponding key is pressed. An interrupt signal is raise in the code, and motors will be executed to perform corresponding action.\r\n\r\n\r\n\r\n", "feature_order": 4, "feature_title": "PS2 Keyboard"}}, {"pk": 5, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 0, "project": 2, "feature_content": "This project used Arduino to control motors via h-bridge motor controller. To control the robot, the user can send signal to Arduino via serial, iPhone, Bluetooth or infrared devices.\r\n\r\n\r\n\r\n", "feature_order": 1, "feature_title": "intro"}}, {"pk": 6, "model": "rankProj.feature", "fields": {"feature_image": "/Images/puppy_robot_feature_2.jpg", "display_choice": 2, "project": 2, "feature_content": "H-bridge takes in PWM signal from Arduino, and uses the strength of this signal to determine how much current it should use to spin the motor. The stronger the signal, the faster the motor spins. \r\n\r\n\r\n\r\n", "feature_order": 2, "feature_title": "H-bridge Motor Controller"}}, {"pk": 7, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 1, "project": 2, "feature_content": "The A-bot can take user input like a remote control car via infrared, Bluetooth, WIFI. Remote controller such as my infrared key chain, iPhone become really handy device if I want to remote control the car wirelessly. When the input is signaled, Arduino micro-controller will interpret the signal and perform the corresponding action.\r\n\r\n\r\n\r\n", "feature_order": 3, "feature_title": "User Input & Output"}}, {"pk": 8, "model": "rankProj.feature", "fields": {"feature_image": "/Images/puppy_robot_feature_3.jpg", "display_choice": 2, "project": 2, "feature_content": "As you can see in the video, the A-bot had some wonderful times with Meijing. After Meijing get familiar with the robot, he decided he want to bite it and see what the robot taste like. Therefore, the next state is definitely design a robot that can take 'bites' from a puppy.  Moreover, with a camera on top of the robot, we can potentially integrate some machine learning algorithm and create more interesting interaction. However, Meijing is not currently with me, I really miss him and I will maybe continue the work if I see him again. \r\n\r\n\r\n\r\n", "feature_order": 4, "feature_title": "Interaction & Future Development"}}, {"pk": 9, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 0, "project": 3, "feature_content": "This project allows users to design their personal light show by programming Arduino mini. All lights installed on the skateboard are controlled by Arduino mini via digital pins. Limited PWM signal can be used to control the intensity of lights.\r\n\r\n\r\n\r\n", "feature_order": 1, "feature_title": "intro"}}, {"pk": 10, "model": "rankProj.feature", "fields": {"feature_image": "/Images/ledskateboard_feature_1.jpg", "display_choice": 2, "project": 3, "feature_content": "To build a solid add-on for the skateboard, I put together 14 transistors and LED lights along with an Arduino mini on the bottom of my skateboard. Each transistor acts as a switch for each LED lights. In order to make sure the lights and wires are well protected, after the board is well soldered, I seal the entire PCB with glue gun. This will not only enhance the life span of the wires, but will also provide reasonable water proof functionality.\r\n\r\n\r\n\r\n", "feature_order": 2, "feature_title": "Light Installation"}}, {"pk": 11, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 1, "project": 3, "feature_content": "In my first prototype, I used 4 AA batteries to charge up all the lights and micro-controller. The batteries can last about two hours, which is satisfactory. However, the main problem comes from the heavy weight of 4 AA batteries. In the second prototype, we switched the AA batteries with lithium ion battery along with a on board rechargeable system. This solution significantly decrease the weight and make the skateboard experience much better.\r\n\r\n\r\n", "feature_order": 3, "feature_title": "Battery Life & Installation"}}, {"pk": 12, "model": "rankProj.feature", "fields": {"feature_image": "/Images/ledskateboard_feature_2.jpg", "display_choice": 2, "project": 3, "feature_content": "Arduino mini is used to be the central controlling unit of the whole system. It can be load custom made light show algorithm created by the user and perform it in a loop. Also, the processor can also take input from external sources such as infrared, Bluetooth to perform remote controlled light show. \r\n\r\n\r\n", "feature_order": 4, "feature_title": "Programmable Processor "}}, {"pk": 13, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 1, "project": 3, "feature_content": "Wireless control is one of the most desirable feature the users want. With wireless control via infrared or Bluetooth, users can change express themselves by changing the pattern of the light show. \r\n\r\n\r\n\r\n", "feature_order": 5, "feature_title": "Wireless Control"}}, {"pk": 14, "model": "rankProj.feature", "fields": {"feature_image": "/Images/ledskateboard_feature_3.jpg", "display_choice": 2, "project": 3, "feature_content": "Besides how cool you can be with all the lights under your feet, these lights can also keep you away from tragic car accidents at night. Due to the low visibility at night, it is very hard for car drivers to see skateboarders if they are skateboarding on the streets. With these lights shining in interesting pattern designed by the user, it will be hard for any car passed by without noticing you.\r\n\r\n\r\n\r\n", "feature_order": 6, "feature_title": "Night Skateboarding & Safety"}}, {"pk": 15, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 0, "project": 4, "feature_content": "This project used photo resistors as the input sensor. Arduino Mega is used to collect input data from the sensors and send corresponding signal the computer. The computer collects signal sent by Arduino and display corresponding audio and video feedback to the user.\r\n\r\n\r\n\r\n", "feature_order": 1, "feature_title": "intro"}}, {"pk": 16, "model": "rankProj.feature", "fields": {"feature_image": "/Images/jp_talk_feature_1.jpg", "display_choice": 2, "project": 4, "feature_content": "Photo resistor is a variable resistor that will change its resistance according to the light intensity in the environment. This project takes advantage of such property to perform key selection for the user. Users are expected to block the light source from the photo resistor by touching the sensor. This action will be interpreted as a key trigger by Arduino processor loaded with our algorithm.\r\n\r\nDue to our target user's physical constraints, photo resistors are chosen over regular press button. The photo resistor not only provides a nice touch experience for the user, but also proofed to be a more robust sensor. It won't detach or lose its bounce like regular press button would over time.  \r\n\r\n\r\n\r\n", "feature_order": 2, "feature_title": "Photo Resistors"}}, {"pk": 17, "model": "rankProj.feature", "fields": {"feature_image": "/Images/jp_talk_feature_2.jpg", "display_choice": 2, "project": 4, "feature_content": "After Arduino Mega processor figure out what key were pressed, it will send the corresponding signal the computer. The algorithm from the computer will collect the signal sent by Arduino and perform audio and visual feedback.\r\n\r\nThe computer performs audio feedback by playing the sound of the corresponding character input by the user. This instant feedback provides a friendly alert to the user what key has been pressed. Visual feedback are performed by simply printing out the Japanese character input by the user.\r\n\r\n\r\n\r\n", "feature_order": 3, "feature_title": "Audio & Visual Feedback"}}, {"pk": 18, "model": "rankProj.feature", "fields": {"feature_image": "/Images/jp_talk_feature_4.jpg", "display_choice": 2, "project": 4, "feature_content": "Without knowing much Japanese, I spent sometimes with my grandfather and figured out there is about 80 Japanese character that are used more frequently in daily conversations. In order to avoid installing 80 light resistors on a signal gloves, I structured all these characters with a certain pattern that only requires 15 light resistors.\r\n\r\nThis particular pattern of input mechanism not only saves a lot of space on the glove, but also very easy to remember since it matches the Japanese language structure perfectly.\r\n\r\n\r\n\r\n", "feature_order": 4, "feature_title": "Japanese Character Structure"}}, {"pk": 19, "model": "rankProj.feature", "fields": {"feature_image": "/Images/jp_talk_feature_3.jpg", "display_choice": 2, "project": 4, "feature_content": "Since the target user does not live in Canada, it was not easy for me to get all the medical information I need to design the glove. Information such as hand size, finger mobility etc. is important information I don't have access to. After making the first prototype with fixed sensor position, I found out that the user is not able to reach certain keys with her finger.\r\n\r\nTherefore, in my second prototype, I designed movable sensors which will not only allow you to move them around when you need to, but also stay still after you decided the perfect position for all your characters.\r\n\r\n\r\n\r\n", "feature_order": 5, "feature_title": "Portable Photo Resistors"}}, {"pk": 20, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 0, "project": 5, "feature_content": "This project uses Neurosky EEG chip to process my own brainwave in real time. We built the essential electronics and software to communicate with EEG chip ourselves and then I implemented machine learning algorithm hoping to find new stable signal to enable us more control in future EEG applications. To make this application real time, the whole project is written in C along with OpenCV and CUDA library.\r\n\r\n\r\n\r\n", "feature_order": 1, "feature_title": "intro"}}, {"pk": 21, "model": "rankProj.feature", "fields": {"feature_image": "/Images/brainwave_feature_1.jpg", "display_choice": 1, "project": 5, "feature_content": "By putting one electrode on the forehead and one electrode on each ear, we can sucessfully read stable brainwave signal via EEG chip. We use Arduino to take in these sensors values and interpret it according NeuroSky API on a standard computer. We applied all sorts of signal processing and transformation method, and I used them as feature hopping to do machine learning algorithm to extract more information out of it.\r\n\r\n\r\n\r\n", "feature_order": 2, "feature_title": "Parsing Real Time EEG Data"}}, {"pk": 22, "model": "rankProj.feature", "fields": {"feature_image": "/Images/brainwave_feature_6_all.jpg", "display_choice": 2, "project": 5, "feature_content": "K-mean algorithm is an unsupervised learning algorithm that can look at all the features in the data set and hard assign all data in k different groups base on how close they are to each other in n-dimensional space. This algorithm is not probabilistic therefore can run sufficiently fast in real time application.  \r\n\r\n\r\n\r\n", "feature_order": 3, "feature_title": "Unsupervised Learning: K-mean Clustering"}}, {"pk": 23, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 0, "project": 6, "feature_content": "This project uses Microsoft Kinect 3D sensors to detect obstacles and signal the user with actuators. It is meant to help blind or visual impaired individual to navigate better in indoor environment.", "feature_order": 1, "feature_title": "intro"}}, {"pk": 24, "model": "rankProj.feature", "fields": {"feature_image": "/Images/kinect_feature_2.jpg", "display_choice": 2, "project": 6, "feature_content": "Microsoft Kinect is used to replace the function of human eye. With Kinect's depth map functionality, we can detect in door obstacles in our daily lives. In real time, the algorithm will determine the location of the obstacle and signal the user with vibrators indicating the direction of the obstacles relative the user.  \r\n", "feature_order": 2, "feature_title": "Microsoft Kinect"}}, {"pk": 25, "model": "rankProj.feature", "fields": {"feature_image": "/Images/kinect_feature_1.jpg", "display_choice": 3, "project": 6, "feature_content": "Actuators(vibrator) is key communication device between the machine and the user. The user uses his/her skin on their forehead to determine the distance and direction of the obstacle. He/She will utilize this information to determine its optimal path in the environment without running into any obstacles. \r\n\r\n\r\n\tThe main challenge with the actuators is to find the best signaling strength to represent different distance between the user and the obstacles. In the first few attempts, we tried to represent the distance between human and obstacles with a linear function. As a result, the user can't really determine how far the object really is because his/her skin cannot really tell the minor difference in vibration. Therefore, the user moves slower among obstacles. In later prototypes, we changed the linear function with other non-linear transfer functions that will change dramatically as the distance  changes.\r\n", "feature_order": 3, "feature_title": "Actuators Distance Sensing"}}, {"pk": 26, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 1, "project": 6, "feature_content": "We applied a 2D Gaussian weight mapping on Kinect's depth map. As a result, the obstacles at the corner of the depth map will vibrate relatively weaker than the obstacles appear at the center of the depth map. Since center is normally the general direction a person is heading, this weight mapping can help users get rid of noise vibration signal.\r\n", "feature_order": 4, "feature_title": "2D Gaussian Mapping"}}, {"pk": 27, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 0, "project": 7, "feature_content": "This project uses several under water microphones ( hydraulophone ) to capture the characteristic of water movement and present it as sound wave through a amplification system. Different sensor represent different musics nodes. Chords and melody can be generated by the user by splashing the water or any other form of water movement created by the user.\r\n", "feature_order": 1, "feature_title": "intro"}}, {"pk": 28, "model": "rankProj.feature", "fields": {"feature_image": "/Images/waterhammer_piano_2.jpg", "display_choice": 2, "project": 7, "feature_content": "Hydraulophone is an invention by Prof. Mann which serves like a under water microphone. In this project, we use it to collect signals created by the user and play music accordingly. With hydraulophone, we are directly translate water movement to music pitch. Thus, the volume of the nodes will change according to the amount of water movement created by the user.\r\n", "feature_order": 2, "feature_title": "Under Water Microphone ( Hydraulophone )"}}, {"pk": 29, "model": "rankProj.feature", "fields": {"feature_image": "/Images/waterhammer_piano_3.jpg", "display_choice": 2, "project": 7, "feature_content": "The position of the sensor is important. Since the objective is to play a melody, not mixing up the nodes is crucial. However, if the sensors are positioned too close to each other, it might pick up signals from its neighbors. Also, ripples and reflection of the water from the wall can also produce noise to the microphone. To find a position to minimize these noise is important.\r\n", "feature_order": 3, "feature_title": "Sensors Positions ( Cross Talking )"}}, {"pk": 30, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 0, "project": 5, "feature_content": "With these brainwave transformation image sets, the objective of the research is to find out if we can identify the the relationship between the brainwave pattern and human thoughts. For example, maybe your brainwave transformation will all look similar when you are hungry.  After running k-mean clustering, we successfully break down the Mix Data Set to the following clusters (Image Cluster 1-4) below. As you can see, each cluster represent one unique pattern of our brainwave transformation. ", "feature_order": 4, "feature_title": "K-mean Clustering Images"}}, {"pk": 31, "model": "rankProj.feature", "fields": {"feature_image": "/Images/brainwave_feature_3.jpg /Images/brainwave_feature_2.jpg", "display_choice": 4, "project": 5, "feature_content": "Feature title, Feature Content is not displayed. Only images are.", "feature_order": 5, "feature_title": "K-mean Clustering Images (Cluster 1 & 2)"}}, {"pk": 32, "model": "rankProj.feature", "fields": {"feature_image": "/Images/brainwave_feature_5.jpg /Images/brainwave_feature_4.jpg", "display_choice": 4, "project": 5, "feature_content": "Feature title, Feature Content is not displayed. Only images are.", "feature_order": 6, "feature_title": "K-mean Clustering Images (Cluster 3 & 4)"}}, {"pk": 33, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 1, "project": 5, "feature_content": "After we sorted out k different groups with K-mean clustering algorithm, we used the separated data sets to train our classifier. Naive Bayes learning algorithm become our number one choice because of its simplicity and efficiency. With the algorithm trained, we can efficiently classify brainwave in real time.", "feature_order": 7, "feature_title": "Training: Naive Bayes Algorithm "}}, {"pk": 34, "model": "rankProj.feature", "fields": {"feature_image": "none", "display_choice": 1, "project": 5, "feature_content": "The project is very successful in terms of the engineering and integration between hardware and software. The training speed and classification speed is very fast since both algorithm was implemented in c. \r\n\r\nHowever, it is not easy for us to find relationship between our classified brainwave and human thoughts. Since this project was implemented without any machine learning training and knowledge at the time. The algorithm was fast, simple and naive. If I have a chance to revisit the problem in the future. I will probably use more sophisticated algorithm such as deep belief net for clustering and svm for training. And will probably use existing machine learning brainwave data sets as our bench mark instead of collecting my own.  ", "feature_order": 8, "feature_title": "Result & Analysis"}}, {"pk": 1, "model": "rankProj.project_type", "fields": {"project": 5, "project_type": "ML"}}, {"pk": 2, "model": "rankProj.project_type", "fields": {"project": 5, "project_type": "HCI"}}, {"pk": 3, "model": "rankProj.project_type", "fields": {"project": 6, "project_type": "HCI"}}, {"pk": 4, "model": "rankProj.project_type", "fields": {"project": 7, "project_type": "HCI"}}, {"pk": 5, "model": "rankProj.project_type", "fields": {"project": 4, "project_type": "HCI"}}, {"pk": 6, "model": "rankProj.project_type", "fields": {"project": 3, "project_type": "HCI"}}, {"pk": 7, "model": "rankProj.project_type", "fields": {"project": 2, "project_type": "HCI"}}, {"pk": 8, "model": "rankProj.project_type", "fields": {"project": 1, "project_type": "HCI"}}, {"pk": 9, "model": "rankProj.project_type", "fields": {"project": 7, "project_type": "ALL"}}, {"pk": 10, "model": "rankProj.project_type", "fields": {"project": 6, "project_type": "ALL"}}, {"pk": 11, "model": "rankProj.project_type", "fields": {"project": 5, "project_type": "ALL"}}, {"pk": 12, "model": "rankProj.project_type", "fields": {"project": 4, "project_type": "ALL"}}, {"pk": 13, "model": "rankProj.project_type", "fields": {"project": 3, "project_type": "ALL"}}, {"pk": 14, "model": "rankProj.project_type", "fields": {"project": 2, "project_type": "ALL"}}, {"pk": 15, "model": "rankProj.project_type", "fields": {"project": 1, "project_type": "ALL"}}, {"pk": 16, "model": "rankProj.project_type", "fields": {"project": 6, "project_type": "PUB"}}, {"pk": 17, "model": "rankProj.project_type", "fields": {"project": 7, "project_type": "PUB"}}]